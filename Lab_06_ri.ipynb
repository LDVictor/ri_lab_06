{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_06_ri.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJLTyu82qf4z",
        "colab_type": "text"
      },
      "source": [
        "# Laboratório 06: Modelo Vetorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0odUa72pqo5n",
        "colab_type": "text"
      },
      "source": [
        "Antes de responder as perguntas deste laboratório, precisamos importar as extensões que usaremos no decorrer da atividade, tais como pandas, numpy, nltk e seaborn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcu3jXRyrfL4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*  **Importação das extensões necessárias** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze0P9bmxrZLt",
        "colab_type": "code",
        "outputId": "7da48b52-46fa-4311-c9b2-10c1bfe951cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import collections\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')\n",
        "import heapq\n",
        "import time\n",
        "import bisect"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdfYJOqisKRo",
        "colab_type": "text"
      },
      "source": [
        "# Questão 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3lcNBd6sR8e",
        "colab_type": "text"
      },
      "source": [
        "**Reconstruir o índice considerando o conjunto de dados que indicamos. Esses são os dados coletados por Bernardi e os estaremos usando para facilitar a correção da atividade.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIP33xNCrolV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*   **Leitura do CSV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaPNEpzirz6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colecao = pd.read_csv('https://raw.githubusercontent.com/LDVictor/ri_lab_06/master/results.csv')\n",
        "documentos = colecao['text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RRE9E9C2DPv",
        "colab_type": "text"
      },
      "source": [
        "*   **Criação dos índices**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wHF3gm-SeuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizador = RegexpTokenizer(r'([A-Za-zÁáÉéÍíÓóÚúÃãÕõÇçÂâÊê]{3,27})')\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese') \n",
        "indices = {}\n",
        "n = 0\n",
        "\n",
        "for texto in documentos:\n",
        "  palavras = [palavra for palavra in tokenizador.tokenize(texto.lower())\n",
        "           if not bool(re.search(r'\\d', palavra))\n",
        "           and palavra not in stopwords and len(palavra) >= 3]  \n",
        "  n += 1\n",
        "  for t in palavras:\n",
        "    if t not in indices.keys():\n",
        "      indices[t] = []\n",
        "    indices[t].append(n)\n",
        "    \n",
        "for elemento in indices.items():\n",
        "  d = dict(collections.Counter(elemento[1]))\n",
        "  indices[elemento[0]] = list(d.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slZPTQtAszjl",
        "colab_type": "text"
      },
      "source": [
        "Agora, temos o índice com o novo conjunto de dados da questão."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYY6t-0bs4Jx",
        "colab_type": "text"
      },
      "source": [
        "# Questão 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCUxjPfIs6Jc",
        "colab_type": "text"
      },
      "source": [
        "**Refinar o índice invertido de forma a também incluir o IDF (inverse document frequency) de cada termo do dicionário.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNSGlMvHfVlc",
        "colab_type": "text"
      },
      "source": [
        "Primeiro, faremos uma função que retorna o IDF do termo passado dado o dicionário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koKSktXDfnxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculaIDF(m, k):\n",
        "  valorIDF = round(np.log((m+1) / k), 2)\n",
        "  return valorIDF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_QgxDSRfuzs",
        "colab_type": "text"
      },
      "source": [
        "Agora, aplicaremos o IDF a cada palavra do ranking, adicionando o IDF ao dicionário em cada termo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxqKwkEx9E8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = colecao.text.count()\n",
        "\n",
        "for palavra in indices:\n",
        "  k = len(indices[palavra])\n",
        "  idf = calculaIDF(m, k)\n",
        "  indices[palavra].append(idf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVLYJuLRFe8l",
        "colab_type": "text"
      },
      "source": [
        "# Questão 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXSqYyvOFg5v",
        "colab_type": "text"
      },
      "source": [
        "**Implementar as seguintes versões do modelo vetorial:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2HV1SrWFlrv",
        "colab_type": "text"
      },
      "source": [
        "**1. Representação binária**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cZCAs3yFvM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modeloVetorialBinario(consulta, documento):\n",
        "  pontos = 0\n",
        "  tokens_documento = documento.split()\n",
        "  tokens_consulta = consulta.split()\n",
        "  \n",
        "  for token in tokens_consulta:\n",
        "    pontos += (token in tokens_documento)\n",
        " \n",
        "  return pontos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enN8qoxhFv3p",
        "colab_type": "text"
      },
      "source": [
        "**2. TF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evHDpnCQF00K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modeloVetorialTF(consulta, documento):\n",
        "  pontos = 0\n",
        "  tokens_documento = documento.split()\n",
        "  tokens_consulta = consulta.split()\n",
        "  \n",
        "  for token in tokens_consulta:\n",
        "    pontos += tokens_documento.count(token)\n",
        "  \n",
        "  return pontos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuwH-4F3F1dm",
        "colab_type": "text"
      },
      "source": [
        "**3. TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4v440yfF5eY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modeloVetorialTFIDF(consulta, documento):\n",
        "  pontos = 0\n",
        "  tokens_documento = documento.split()\n",
        "  tokens_consulta = consulta.split()\n",
        "  \n",
        "  for token in tokens_consulta:\n",
        "    cwd = tokens_documento.count(token)\n",
        "    pontos += cwd * indices[token][-1]\n",
        "  \n",
        "  return round(pontos, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL76bcDuF6CP",
        "colab_type": "text"
      },
      "source": [
        "**4. BM25***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Klo8gnvF_Zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modeloVetorialBM25(consulta, documento, n):\n",
        "  pontos = 0\n",
        "  tokens_documento = documento.split()\n",
        "  tokens_consulta = consulta.split()\n",
        "  \n",
        "  palavras = [palavra for palavra in tokens_consulta if palavra in tokens_documento]\n",
        "    \n",
        "  for palavra in palavras:\n",
        "    cwd = tokens_documento.count(palavra)\n",
        "    dfw = len(indices[palavra][:-1])\n",
        "    pontos += (((k+1) * cwd) / (cwd + k)) * np.log10(((m+1) / dfw))\n",
        "  \n",
        "  return round(pontos, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWnqX0xUGCy_",
        "colab_type": "text"
      },
      "source": [
        "# Questão 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxGXaZkVGELX",
        "colab_type": "text"
      },
      "source": [
        "**Execute os algoritmos separadamente em 3 consultas de sua escolha e retorne os top-5 documentos mais similares à cada consulta.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiDVLdglNFNv",
        "colab_type": "text"
      },
      "source": [
        "Como primeiro passo, definiremos as 3 consultas para fazer o experimento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvBvcFXbNNop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "consultas = ['educação', 'governo', 'bolsonaro']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE1kuG0OPZrF",
        "colab_type": "text"
      },
      "source": [
        "Agora, criaremos a função que retorna os top-5 documentos mais similares às consultas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiApoo3aPuVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def top5Documentos(consulta):\n",
        "  n = 0\n",
        "  d_binaria = []\n",
        "  d_tf = []\n",
        "  d_tfidf = []\n",
        "  d_bm25 = []\n",
        "  for documento in colecao.text:\n",
        "    documento = documento.lower()\n",
        "    n += 1\n",
        "    bisect.insort(d_binaria, (modeloVetorialBinario(consulta, documento), n))\n",
        "    bisect.insort(d_tf, (modeloVetorialTF(consulta, documento), n))\n",
        "    bisect.insort(d_tfidf, (modeloVetorialTFIDF(consulta, documento), n))\n",
        "    bisect.insort(d_bm25, (modeloVetorialBM25(consulta, documento, 10), n))\n",
        "  \n",
        "  d_binaria.reverse()\n",
        "  d_tf.reverse()\n",
        "  d_tfidf.reverse()\n",
        "  d_bm25.reverse()\n",
        "  \n",
        "  return d_binaria[:5], d_tf[:5], d_tfidf[:5], d_bm25[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwXxbVzgRqy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "binario_top5 = ['','','']\n",
        "tf_top5 = ['','','']\n",
        "tfidf_top5 = ['','','']\n",
        "bm25_top5 = ['','','']\n",
        "\n",
        "binario_top5[0], tf_top5[0], tfidf_top5[0], bm25_top5[0] = top5Documentos(consultas[0])\n",
        "binario_top5[1], tf_top5[1], tfidf_top5[1], bm25_top5[1] = top5Documentos(consultas[1])\n",
        "binario_top5[2], tf_top5[2], tfidf_top5[2], bm25_top5[2] = top5Documentos(consultas[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t04eFQfV51H",
        "colab_type": "text"
      },
      "source": [
        "Por fim, montaremos a tabela para mostrar os dados calculados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63s4xWhqWCuu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "c764d43b-517c-4189-ee88-8a8a775b0b71"
      },
      "source": [
        "tabela_q4 = pd.DataFrame()\n",
        "\n",
        "tabela_q4['Consulta'] = consultas\n",
        "tabela_q4['Binário'] = binario_top5\n",
        "tabela_q4['TF'] = tf_top5\n",
        "tabela_q4['TF-IDF'] = tfidf_top5\n",
        "tabela_q4['BM25*'] = bm25_top5\n",
        "\n",
        "tabela_q4.index += 1\n",
        "tabela_q4"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Consulta</th>\n",
              "      <th>Binário</th>\n",
              "      <th>TF</th>\n",
              "      <th>TF-IDF</th>\n",
              "      <th>BM25*</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>educação</td>\n",
              "      <td>[(1, 248), (1, 240), (1, 239), (1, 233), (1, 2...</td>\n",
              "      <td>[(15, 221), (8, 222), (6, 239), (6, 130), (5, ...</td>\n",
              "      <td>[(32.85, 221), (17.52, 222), (13.14, 239), (13...</td>\n",
              "      <td>[(1.78, 221), (1.69, 222), (1.63, 239), (1.63,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>governo</td>\n",
              "      <td>[(1, 249), (1, 248), (1, 246), (1, 245), (1, 2...</td>\n",
              "      <td>[(14, 173), (12, 166), (10, 248), (9, 115), (8...</td>\n",
              "      <td>[(12.46, 173), (10.68, 166), (8.9, 248), (8.01...</td>\n",
              "      <td>[(0.72, 173), (0.71, 166), (0.7, 248), (0.69, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bolsonaro</td>\n",
              "      <td>[(1, 248), (1, 240), (1, 238), (1, 237), (1, 2...</td>\n",
              "      <td>[(32, 151), (30, 207), (30, 166), (19, 19), (1...</td>\n",
              "      <td>[(42.24, 151), (39.6, 207), (39.6, 166), (25.0...</td>\n",
              "      <td>[(1.11, 207), (1.11, 166), (1.11, 151), (1.09,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Consulta  ...                                              BM25*\n",
              "1   educação  ...  [(1.78, 221), (1.69, 222), (1.63, 239), (1.63,...\n",
              "2    governo  ...  [(0.72, 173), (0.71, 166), (0.7, 248), (0.69, ...\n",
              "3  bolsonaro  ...  [(1.11, 207), (1.11, 166), (1.11, 151), (1.09,...\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-_Tk4QBGW_Y",
        "colab_type": "text"
      },
      "source": [
        "# Questão 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmIvhYcVGddA",
        "colab_type": "text"
      },
      "source": [
        "**Compare os resultados encontrados e responda.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FZXqSQAGhWD",
        "colab_type": "text"
      },
      "source": [
        "**1. Quais modelos você acha que trouxe os melhores resultados? Por que? Inspecione os documentos retornados para melhor embasar sua resposta.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAK_pBFAGlYo",
        "colab_type": "text"
      },
      "source": [
        "De acordo com os dados apresentados, acredito que o modelo BM25* apresentou resultados mais convincentes, pois demonstrou mais precisão com relação às consultas definidas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3vxxVIVGmjO",
        "colab_type": "text"
      },
      "source": [
        "**Calcule e reporte o overlap par-a-par entre os resultados de cada modelo.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydUk7JeKGqn-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1897b9e1-12dd-4644-a52f-6a5919b4788b"
      },
      "source": [
        "..."
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SHNI5H2Gr46",
        "colab_type": "text"
      },
      "source": [
        "..."
      ]
    }
  ]
}